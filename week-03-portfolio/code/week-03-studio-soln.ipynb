{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering\n",
      "DATASETS_DIR: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets\n",
      "DATA_DIR: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets/08\n",
      "W1_FILE: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets/08/ampc/w1.csv\n",
      "W2_FILE: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets/08/ampc/w2.csv\n",
      "W3_FILE: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets/08/ampc/w3.csv\n",
      "W4_FILE: E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering/datasets/08/ampc/w4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "HOME_DIR = 'E:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering'\n",
    "os.chdir(HOME_DIR)\n",
    "\n",
    "DATASETS_DIR = f'{HOME_DIR}/datasets'\n",
    "DATA_DIR = f'{DATASETS_DIR}/08'\n",
    "W1_FILE = f'{DATA_DIR}/ampc/w1.csv'\n",
    "W2_FILE = f'{DATA_DIR}/ampc/w2.csv'\n",
    "W3_FILE = f'{DATA_DIR}/ampc/w3.csv'\n",
    "W4_FILE = f'{DATA_DIR}/ampc/w4.csv'\n",
    "\n",
    "print(f'HOME_DIR: {HOME_DIR}')\n",
    "print(f'DATASETS_DIR: {DATASETS_DIR}')\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'W1_FILE: {W1_FILE}')\n",
    "print(f'W2_FILE: {W2_FILE}')\n",
    "print(f'W3_FILE: {W3_FILE}')\n",
    "print(f'W4_FILE: {W4_FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering\\venv\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\#Projects\\COS40007-Artificial-Intelligence-for-Engineering\\venv\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.integrate import simpson as simps\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "w1 = pd.read_csv(W1_FILE)\n",
    "w2 = pd.read_csv(W2_FILE)\n",
    "w3 = pd.read_csv(W3_FILE)\n",
    "w4 = pd.read_csv(W4_FILE)\n",
    "\n",
    "# Combine the datasets\n",
    "combined_data = pd.concat([w1, w2, w3, w4])\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_data_file = f'{DATA_DIR}/combined_data.csv'\n",
    "combined_data.to_csv(combined_data_file, index=False)\n",
    "\n",
    "print(f'Combined data saved to: {combined_data_file}')\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(combined_data.info())\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(f\"Dataset Shape: {combined_data.shape}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(combined_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = combined_data.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable (last column)\n",
    "class_distribution = combined_data.iloc[:, -1].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Plot the class distribution\n",
    "sns.countplot(x=combined_data.columns[-1], data=combined_data)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = combined_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the first 5 features as an example\n",
    "combined_data.iloc[:, :5].hist(bins=20, figsize=(15, 10))\n",
    "plt.suptitle(\"Distribution of First 5 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots to check for outliers in the first 5 features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(data=combined_data.iloc[:, i])\n",
    "    plt.title(f'Feature {i+1} Boxplot')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variance of all features\n",
    "feature_variances = combined_data.var()\n",
    "print(\"Variance of Features:\")\n",
    "print(feature_variances.sort_values(ascending=False).head(10))  # Display top 10 features with highest variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of each feature with the target variable\n",
    "target_corr = correlation_matrix.iloc[:, -1].sort_values(ascending=False)\n",
    "print(\"Correlation with Target Variable:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the Data and Save to all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the combined dataset\n",
    "shuffled_data = combined_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Save the shuffled data to a new CSV file\n",
    "all_data_file = f'{DATA_DIR}/all_data.csv'\n",
    "shuffled_data.to_csv(all_data_file, index=False)\n",
    "\n",
    "print(f'Shuffled data saved to: {all_data_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: DATASET TOO LARGE AND TAKES FOREVER TO RUN ON THE MACHINE SO INSTEAD OF TAKING ALL DATA, WE WILL TAKE A SAMPLE OF THE DATA FOR TRAINING AND TESTING\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "shuffled_data = combined_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Sample 1% of the shuffled data\n",
    "sampled_data = shuffled_data.sample(frac=0.01, random_state=1)\n",
    "\n",
    "# Save the sampled and shuffled data to a new CSV file\n",
    "sampled_data_file = f'{DATA_DIR}/sampled_all_data.csv'\n",
    "sampled_data.to_csv(sampled_data_file, index=False)\n",
    "\n",
    "print(f'Sampled and shuffled data saved to: {sampled_data_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the SVM Model with Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "all_data = pd.read_csv(sampled_data_file)\n",
    "\n",
    "# Separate features and labels\n",
    "X = all_data.iloc[:, :-1]  # All columns except the last one\n",
    "y = all_data.iloc[:, -1]  # The last column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Train the SVM model\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy on test set: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "print(f'Cross-validation accuracy: {scores.mean():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and accuracy\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain the SVM Model with Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model using the best parameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Train and test split accuracy\n",
    "best_clf.fit(X_train, y_train)\n",
    "y_pred_best = best_clf.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Accuracy with tuned parameters on test set: {accuracy_best:.2f}')\n",
    "\n",
    "# Cross-validation accuracy with tuned parameters\n",
    "scores_best = cross_val_score(best_clf, X, y, cv=10)\n",
    "print(f'Cross-validation accuracy with tuned parameters: {scores_best.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using K-Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 100 features\n",
    "k_best = SelectKBest(f_classif, k=100)\n",
    "X_k_best = k_best.fit_transform(X, y)\n",
    "\n",
    "# Train and evaluate with the selected features\n",
    "X_train_k, X_test_k, y_train_k, y_test_k = train_test_split(X_k_best, y, test_size=0.3, random_state=1)\n",
    "clf_k_best = svm.SVC(kernel='linear')\n",
    "clf_k_best.fit(X_train_k, y_train_k)\n",
    "y_pred_k_best = clf_k_best.predict(X_test_k)\n",
    "accuracy_k_best = accuracy_score(y_test_k, y_pred_k_best)\n",
    "print(f'Accuracy with K-Best features on test set: {accuracy_k_best:.2f}')\n",
    "\n",
    "# Cross-validation accuracy with K-Best features\n",
    "scores_k_best = cross_val_score(clf_k_best, X_k_best, y, cv=10)\n",
    "print(f'Cross-validation accuracy with K-Best features: {scores_k_best.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA and select top 10 components\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Train and evaluate with the PCA features\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=1)\n",
    "clf_pca = svm.SVC(kernel='linear')\n",
    "clf_pca.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = clf_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test_pca, y_pred_pca)\n",
    "print(f'Accuracy with PCA features on test set: {accuracy_pca:.2f}')\n",
    "\n",
    "# Cross-validation accuracy with PCA features\n",
    "scores_pca = cross_val_score(clf_pca, X_pca, y, cv=10)\n",
    "print(f'Cross-validation accuracy with PCA features: {scores_pca.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = {\n",
    "    'Model': ['Original features', 'With hyperparameter tuning', 'With K-Best features', 'With PCA features'],\n",
    "    'Train-test split accuracy': [accuracy, accuracy_best, accuracy_k_best, accuracy_pca],\n",
    "    'Cross-validation accuracy': [scores.mean(), scores_best.mean(), scores_k_best.mean(), scores_pca.mean()]\n",
    "}\n",
    "\n",
    "summary_table = pd.DataFrame(summary_data)\n",
    "print(summary_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
